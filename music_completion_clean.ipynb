{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music generation notebook\n",
    "\n",
    "In this notebook we provide minimal replication guidelines of the music generation part of our work. \n",
    "The main code to replicate all of our plots and results sits in the highly unstructured music_generation.ipynb.\n",
    "\n",
    "First, we need to import all relevant packages (virtual environment needed for all of this to work can be provided upon request):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"  # uncomment this if you dont want to use GPU\n",
    "\n",
    "import pretty_midi\n",
    "import midi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Lambda, Concatenate, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "import sys\n",
    "from sys import stdout\n",
    "import random\n",
    "\n",
    "import librosa.display\n",
    "import pypianoroll\n",
    "\n",
    "import scipy.stats as st\n",
    "from os import path\n",
    "import pickle\n",
    "\n",
    "\n",
    "################################### Our code\n",
    "\n",
    "from loading import *\n",
    "from models import *\n",
    "from data import *\n",
    "from midi_to_statematrix import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"GPU is available: {}\".format(tf.test.is_gpu_available()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above should print:\n",
    "\n",
    "TensorFlow version: 2.0.0 \\\n",
    "GPU is available: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train our best model (bi-axial LSTM for both encoder and decoder) type this in bash console (takes around 50h to train):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{bash}\n",
    "python3 train_biaxial_long.py -lr 0.001 -bs 64 \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now the encoder output size is fixed to 32, which can be easily changed in the train_biaxial_long.py script. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we give our generation process in one jupyter notebook cell. It involves the model going one timestep at a time and predicting the entire sequence in the target patch. We provide flexibility in the high level parameters of the generation process, which are mostly connected in translating probabilities from the model into actually played notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### GENERATION PARAMETERS #####################\n",
    "\n",
    "my_model_name = \"biaxial_pn_encoder_concat_deeplstm_cont.h5\" # name of model in .h5 format\n",
    "foldername    = 'experiment_switch_order3'                   # folder where to save the output of generation\n",
    "\n",
    "# data \n",
    "what_type = 'test'    # can be train or test\n",
    "train_tms = 40        # length of the context in timesteps\n",
    "test_tms = 20         # length of the target in timesteps\n",
    "batch_size = 64       # size of the batch (we will generate batch_size patches)\n",
    "songs_per_batch = 16  # how many different piano scores we want per batch (must divide batch_size)\n",
    "seed = 1212           # random seed for replication (applies only to choosing scores and patch start times)\n",
    "\n",
    "\n",
    "# turn_probabilities_to_notes params\n",
    "how = 'random'              # look into function for more details\n",
    "normalize = False           # whether to normalize the probabilities outputted from the model\n",
    "remap_to_max = True         # whether to divide probabilities by the max probability in that timestep\n",
    "turn_on_notes = 8           # how many notes we want to turn on maximally at any timestep (humans have 10 fingers)\n",
    "divide_prob = 2             # value by which we divide probabilities\n",
    "articulation_prob = 0.0018  # if probability of stroking note is higher than that and it was played in last timestep then we articulate\n",
    "remap_prob = 0.35           # if remap_to_max is True, this is the value we multiply the resulting probabilities by\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now running the below will generate the patches and save them to foldername:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(file, curr_batch, modelname, *modelparams):\n",
    "    new_model = modelname(curr_batch, *modelparams)\n",
    "    \n",
    "    new_model.load_weights(file)\n",
    "    \n",
    "    return new_model\n",
    "\n",
    "def turn_probabilities_to_notes(prediction, \n",
    "                                turn_on, \n",
    "                                how = 'random', \n",
    "                                normalize = True, \n",
    "                                threshold = 0.1, \n",
    "                                divide_prob = 2,\n",
    "                                remap_to_max = True):\n",
    "    \n",
    "    for batch in range(prediction.shape[0]):\n",
    "        if turn_on[batch] <= 1:\n",
    "            prediction[batch, :] = 0\n",
    "            continue\n",
    "        turn_off = prediction[batch, :].argsort()[:-int(turn_on[batch])]\n",
    "        prediction[batch, :][turn_off] = 0\n",
    "        \n",
    "        if normalize: \n",
    "            prediction[batch, timestep, :] = st.norm.cdf((prediction[batch, timestep, :] - \n",
    "                                                np.mean(prediction[batch, timestep, :][prediction[batch, timestep, :] > 0]))/\n",
    "                                               np.sqrt(np.var(prediction[batch, timestep, :][prediction[batch, timestep, :]>0])))/divide_prob\n",
    "            prediction[batch, timestep, :][turn_off] = 0\n",
    "        \n",
    "        if remap_to_max:\n",
    "            prediction[batch, :] /= prediction[batch, :].max()\n",
    "            prediction[batch, :] *= remap_prob\n",
    "        \n",
    "    if how == 'random':\n",
    "        \n",
    "        notes =  np.random.binomial(1, p=prediction)\n",
    "        \n",
    "    elif how == 'random_thresholded':\n",
    "        \n",
    "        prediction[prediction >= threshold] += 0.5\n",
    "        prediction[prediction > 1] = 1\n",
    "        prediction[prediction < threshold] = 0\n",
    "        \n",
    "        notes =  np.random.binomial(1, p=prediction)\n",
    "        \n",
    "    elif how == 'thresholded':\n",
    "        \n",
    "        prediction[prediction >= threshold] = 1\n",
    "        prediction[prediction < threshold] = 0\n",
    "        \n",
    "        notes = prediction\n",
    "    \n",
    "    return notes     \n",
    "\n",
    "############################################# LOAD DATA ####################################################\n",
    "\n",
    "file = 'maestro-v2.0.0/maestro-v2.0.0.csv'\n",
    "# Get a batch we want to predict\n",
    "data_test = DataObject(file, what_type = what_type, \n",
    "                       train_tms = train_tms, test_tms = test_tms, \n",
    "                       fs = 20, window_size = 15,\n",
    "                       seed = seed)\n",
    "\n",
    "# Create a batch class which we will iterate over\n",
    "test_batch = Batch(data_test, batch_size = batch_size, songs_per_batch = songs_per_batch)\n",
    "\n",
    "\n",
    "############################################# START GENERATING #############################################\n",
    "\n",
    "curr_test_batch = copy.deepcopy(test_batch.data)\n",
    "\n",
    "# Uncomment below line if you want to switch the ordering of the contexts\n",
    "#curr_test_batch.context[[0,1],:,:,:] = curr_test_batch.context[[1,0],:,:,:]\n",
    "\n",
    "final_output = np.zeros((test_batch.batch_size, \n",
    "                         19+data_test.test_tms+19, \n",
    "                         78))\n",
    "\n",
    "# The next is not necessary but makes the samples a bit better\n",
    "# Populate from the front\n",
    "final_output[:,0:19,:] = curr_test_batch.context[0,:,-19:,:]\n",
    "final_output[:,20,:] = DataObject.drop_articulation3d(curr_test_batch.target[:,0,:,:])\n",
    "\n",
    "# Populate from the back \n",
    "final_output[:,-19:,:] = curr_test_batch.context[1,:,0:19,:]\n",
    "\n",
    "curr_test_batch.target[:,0:20,:,0] = final_output[:,0:20,:]\n",
    "curr_test_batch.target[:,0:20,:,1] = np.zeros(final_output[:,0:20,:].shape)\n",
    "\n",
    "curr_test_batch.target_split = 0\n",
    "curr_test_batch.window_size  = 20\n",
    "curr_test_batch.featurize(use_biaxial = True)\n",
    "\n",
    "# If you have trained a different model from the models.py file, change the last argument of the next function to that models name\n",
    "model = load_model(my_model_name, curr_test_batch, biaxial_pn_encoder_concat_deeplstm)\n",
    "\n",
    "def take_prediction(t):\n",
    "    if t<20:\n",
    "        return -t\n",
    "    else:\n",
    "        return -20\n",
    "\n",
    "def take_actual(t):\n",
    "    if t <= test_tms:\n",
    "        return np.arange(19, 19+t, 1)\n",
    "    else:\n",
    "        return np.arange(t-test_tms+19, t-19, 1)\n",
    "\n",
    "# Start looping over the target patch\n",
    "for timestep in range(1,test_tms):\n",
    "    \n",
    "    stdout.write('\\rtimestep {}/{}'.format(timestep, test_tms))\n",
    "    stdout.flush()\n",
    "    \n",
    "    prediction = model.predict([tf.convert_to_tensor(curr_test_batch.context, dtype = tf.float32), \n",
    "                                tf.convert_to_tensor(curr_test_batch.target_train, dtype = tf.float32)],\n",
    "                               steps = 1)[:,take_prediction(timestep):,:]\n",
    "    \n",
    "    notes = np.zeros(prediction.shape)\n",
    "    \n",
    "    turn_on = [turn_on_notes]*batch_size\n",
    "    \n",
    "    # Loop over notes to determine which one to play\n",
    "    for t in range(notes.shape[1]):\n",
    "        articulation = np.multiply(prediction[:,t,:], final_output[:,20+t,:])\n",
    "        articulation[articulation >= articulation_prob] = 1\n",
    "        articulation[articulation < articulation_prob] = 0\n",
    "        articulated_notes = np.sum(articulation, axis = -1)\n",
    "        \n",
    "        play_notes = turn_probabilities_to_notes(prediction[:,t,:], \n",
    "                                        turn_on = turn_on - articulated_notes,\n",
    "                                        how = 'random', \n",
    "                                        normalize = normalize,\n",
    "                                        divide_prob = divide_prob, \n",
    "                                        remap_to_max = remap_to_max)\n",
    "        \n",
    "        play_notes = play_notes + articulation\n",
    "        play_notes[play_notes >= 1] = 1\n",
    "        play_notes[play_notes < 1] = 0\n",
    "        \n",
    "        final_output[:,21+t,:] = play_notes\n",
    "    \n",
    "    \n",
    "    # Now reinitialize the model and everything (quite an inefficient implementation)\n",
    "    curr_test_batch = copy.deepcopy(test_batch.data)\n",
    "    \n",
    "    curr_test_batch.target[:,0:20,:,0] = final_output[:,timestep:(20+timestep)]\n",
    "\n",
    "    curr_test_batch.target_split = 0\n",
    "    curr_test_batch.window_size  = 20\n",
    "    curr_test_batch.featurize(use_biaxial = True)\n",
    "\n",
    "    # End of timestep loop\n",
    "    \n",
    "true_batch = copy.deepcopy(test_batch.data)\n",
    "\n",
    "# This enables us to save the patches with the actual score names they come from\n",
    "song_names = np.zeros(len(true_batch.link))\n",
    "song_names = song_names.tolist()\n",
    "i = 0\n",
    "for i, link in enumerate(true_batch.link):\n",
    "    with open(data_test.file) as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            line_count = 0\n",
    "\n",
    "            for row in csv_reader:\n",
    "                if line_count == 0:\n",
    "                    line_count += 1\n",
    "                else:\n",
    "                    if row[4] == link:\n",
    "                        name = str(row[0]) + '_' + str(row[1]) + '___' + str(i)\n",
    "                        name = name.replace(\" \", \"-\")\n",
    "                        name = name.replace(\"/\", \"\")\n",
    "                        song_names[i] = name\n",
    "                        break  \n",
    "\n",
    "##########################################################                      \n",
    "\n",
    "if path.isdir(foldername):\n",
    "    os.system('rm -r {}'.format(foldername))\n",
    "\n",
    "if not path.isdir(foldername):\n",
    "    os.mkdir(foldername)\n",
    "\n",
    "with open('{}/setup.txt'.format(foldername), 'w+') as f:\n",
    "    f.write('what_type = {} \\n \\\n",
    "             train_tms = {} \\n \\\n",
    "             test_tms  = {} \\n \\\n",
    "             batch_size = {} \\n \\\n",
    "             songs_per_batch ={} \\n \\\n",
    "             how = {} \\n \\\n",
    "             normalize = {} \\n \\\n",
    "             turn_on = {} \\n \\\n",
    "             divide_prob = {} \\n \\\n",
    "             articulation_prob = {}'.format(what_type,\n",
    "                                            str(train_tms),\n",
    "                                            str(test_tms),\n",
    "                                            str(batch_size),\n",
    "                                            str(songs_per_batch),\n",
    "                                            how,\n",
    "                                            str(normalize),\n",
    "                                            str(turn_on[0]),\n",
    "                                            str(divide_prob),\n",
    "                                            str(articulation_prob)))\n",
    "\n",
    "##########################################################\n",
    "\n",
    "true_batch = copy.deepcopy(test_batch.data)\n",
    "\n",
    "true_batch.target = DataObject.drop_articulation(true_batch.target)\n",
    "\n",
    "# Combine context\n",
    "true_sample = np.append(np.squeeze(curr_test_batch.context[:,0,:,:]), true_batch.target, axis = 1)\n",
    "true_sample = np.append(true_sample, np.squeeze(curr_test_batch.context[:,1,:,:]), axis = 1)\n",
    "\n",
    "true_sample = np.append(np.expand_dims(true_sample, axis = 3), \n",
    "                                  np.expand_dims(true_sample, axis = 3), axis = 3)\n",
    "\n",
    "predicted_sample = np.append(np.squeeze(curr_test_batch.context[:,0,:,:]), final_output[:,20:(20+test_tms),:], axis = 1)\n",
    "predicted_sample = np.append(predicted_sample, np.squeeze(curr_test_batch.context[:,1,:,:]), axis = 1)\n",
    "\n",
    "predicted_sample = np.append(np.expand_dims(predicted_sample, axis = 3), \n",
    "                                       np.expand_dims(predicted_sample, axis = 3), axis = 3)\n",
    "\n",
    "# Save final midi\n",
    "\n",
    "save_indices = np.arange(0,test_batch.batch_size)\n",
    "for idx, i in enumerate(save_indices):\n",
    "    print(\"saving {}\".format(idx))\n",
    "\n",
    "    noteStateMatrixToMidi(true_sample[i,:,:], name = '{}/NO_{}_TRUE_{}'.format(foldername,i,song_names[i]))\n",
    "    noteStateMatrixToMidi(predicted_sample[i,:,:], name = '{}/NO_{}_PRED_{}'.format(foldername,i,song_names[i]))                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_batch_element2(batch, fig, which_element = 0, cmap_ctx = 'viridis', cmap_tar = 'Reds', num_subplot = 2):\n",
    "    ax = fig.add_subplot(300 + 10 + num_subplot)\n",
    "    \n",
    "    full_segment = combine_pianoroll(batch.context[which_element,0,:,:],\n",
    "                                     np.zeros(batch.target[which_element,:,:].shape),\n",
    "                                     batch.context[which_element,1,:,:])\n",
    "    \n",
    "    just_target = np.zeros(full_segment.shape)\n",
    "    just_target[40:60, :] = batch.target[which_element,:,:]\n",
    "    \n",
    "    plot_pianoroll(ax, full_segment, cmap = cmap_ctx)\n",
    "    plot_pianoroll(ax, just_target,  cmap = cmap_tar, alpha = 1)\n",
    "    ax.axvline(data_test.train_tms)\n",
    "    ax.axvline(data_test.train_tms+data_test.test_tms)\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "def pad_with_zeros(pianoroll):\n",
    "    return np.pad(pianoroll, ((0,0),(25, 25)), 'constant', constant_values=(0, 0))\n",
    "\n",
    "def combine_pianoroll(*pianorolls):\n",
    "    \n",
    "    for idx, pianoroll in enumerate(pianorolls):\n",
    "        if idx == 0:\n",
    "            new_pianoroll = pianoroll\n",
    "        else:\n",
    "            new_pianoroll = np.append(new_pianoroll, pianoroll, axis = 0)\n",
    "    \n",
    "    return new_pianoroll\n",
    "\n",
    "def plot_batch_element(batch, which_element = 0, cmap_ctx = 'viridis', cmap_tar = 'Reds', num_subplots = 3, figsize = (12,8)):\n",
    "    fig = plt.figure(figsize = figsize)\n",
    "    ax = fig.add_subplot(num_subplots*100 + 11)\n",
    "    \n",
    "    full_segment = combine_pianoroll(batch.context[which_element,0,:,:],\n",
    "                                     np.zeros(DataObject.drop_articulation3d(batch.target[which_element,:,:]).shape),\n",
    "                                     batch.context[which_element,1,:,:])\n",
    "    \n",
    "    just_target = np.zeros(full_segment.shape)\n",
    "    just_target[40:60, :] = DataObject.drop_articulation3d(batch.target[which_element,:,:])\n",
    "    \n",
    "    plot_pianoroll(ax, full_segment, cmap = cmap_ctx)\n",
    "    plot_pianoroll(ax, just_target,  cmap = cmap_tar, alpha = 1)\n",
    "    ax.axvline(data_test.train_tms)\n",
    "    ax.axvline(data_test.train_tms+data_test.test_tms)\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "# The next function is a modified function from the packacge pypianoroll\n",
    "def plot_pianoroll(\n",
    "    ax,\n",
    "    pianoroll,\n",
    "    is_drum=False,\n",
    "    beat_resolution=None,\n",
    "    downbeats=None,\n",
    "    preset=\"default\",\n",
    "    cmap=\"Blues\",\n",
    "    xtick=\"auto\",\n",
    "    ytick=\"octave\",\n",
    "    xticklabel=True,\n",
    "    yticklabel=\"auto\",\n",
    "    tick_loc=None,\n",
    "    tick_direction=\"in\",\n",
    "    label=\"both\",\n",
    "    grid=\"both\",\n",
    "    grid_linestyle=\":\",\n",
    "    grid_linewidth=0.5,\n",
    "    num_notes = 78,\n",
    "    x_start = 1,\n",
    "    alpha = 1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a pianoroll given as a numpy array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax : matplotlib.axes.Axes object\n",
    "        A :class:`matplotlib.axes.Axes` object where the pianoroll will be\n",
    "        plotted on.\n",
    "    pianoroll : np.ndarray\n",
    "        A pianoroll to be plotted. The values should be in [0, 1] when data type\n",
    "        is float, and in [0, 127] when data type is integer.\n",
    "\n",
    "        - For a 2D array, shape=(num_time_step, num_pitch).\n",
    "        - For a 3D array, shape=(num_time_step, num_pitch, num_channel), where\n",
    "          channels can be either RGB or RGBA.\n",
    "\n",
    "    is_drum : bool\n",
    "        A boolean number that indicates whether it is a percussion track.\n",
    "        Defaults to False.\n",
    "    beat_resolution : int\n",
    "        The number of time steps used to represent a beat. Required and only\n",
    "        effective when `xtick` is 'beat'.\n",
    "    downbeats : list\n",
    "        An array that indicates whether the time step contains a downbeat (i.e.,\n",
    "        the first time step of a bar).\n",
    "\n",
    "    preset : {'default', 'plain', 'frame'}\n",
    "        A string that indicates the preset theme to use.\n",
    "\n",
    "        - In 'default' preset, the ticks, grid and labels are on.\n",
    "        - In 'frame' preset, the ticks and grid are both off.\n",
    "        - In 'plain' preset, the x- and y-axis are both off.\n",
    "\n",
    "    cmap :  `matplotlib.colors.Colormap`\n",
    "        The colormap to use in :func:`matplotlib.pyplot.imshow`. Defaults to\n",
    "        'Blues'. Only effective when `pianoroll` is 2D.\n",
    "    xtick : {'auto', 'beat', 'step', 'off'}\n",
    "        A string that indicates what to use as ticks along the x-axis. If 'auto'\n",
    "        is given, automatically set to 'beat' if `beat_resolution` is also given\n",
    "        and set to 'step', otherwise. Defaults to 'auto'.\n",
    "    ytick : {'octave', 'pitch', 'off'}\n",
    "        A string that indicates what to use as ticks along the y-axis.\n",
    "        Defaults to 'octave'.\n",
    "    xticklabel : bool\n",
    "        Whether to add tick labels along the x-axis. Only effective when `xtick`\n",
    "        is not 'off'.\n",
    "    yticklabel : {'auto', 'name', 'number', 'off'}\n",
    "        If 'name', use octave name and pitch name (key name when `is_drum` is\n",
    "        True) as tick labels along the y-axis. If 'number', use pitch number. If\n",
    "        'auto', set to 'name' when `ytick` is 'octave' and 'number' when `ytick`\n",
    "        is 'pitch'. Defaults to 'auto'. Only effective when `ytick` is not\n",
    "        'off'.\n",
    "    tick_loc : tuple or list\n",
    "        The locations to put the ticks. Availables elements are 'bottom', 'top',\n",
    "        'left' and 'right'. Defaults to ('bottom', 'left').\n",
    "    tick_direction : {'in', 'out', 'inout'}\n",
    "        A string that indicates where to put the ticks. Defaults to 'in'. Only\n",
    "        effective when one of `xtick` and `ytick` is on.\n",
    "    label : {'x', 'y', 'both', 'off'}\n",
    "        A string that indicates whether to add labels to the x-axis and y-axis.\n",
    "        Defaults to 'both'.\n",
    "    grid : {'x', 'y', 'both', 'off'}\n",
    "        A string that indicates whether to add grids to the x-axis, y-axis, both\n",
    "        or neither. Defaults to 'both'.\n",
    "    grid_linestyle : str\n",
    "        Will be passed to :meth:`matplotlib.axes.Axes.grid` as 'linestyle'\n",
    "        argument.\n",
    "    grid_linewidth : float\n",
    "        Will be passed to :meth:`matplotlib.axes.Axes.grid` as 'linewidth'\n",
    "        argument.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if pianoroll.ndim not in (2, 3):\n",
    "        raise ValueError(\"`pianoroll` must be a 2D or 3D numpy array\")\n",
    "    if pianoroll.shape[1] != num_notes:\n",
    "        raise ValueError(\"The length of the second axis of `pianoroll` must be 128.\")\n",
    "    if xtick not in (\"auto\", \"beat\", \"step\", \"off\"):\n",
    "        raise ValueError(\"`xtick` must be one of {'auto', 'beat', 'step', 'none'}.\")\n",
    "    if xtick == \"beat\" and beat_resolution is None:\n",
    "        raise ValueError(\"`beat_resolution` must be specified when `xtick` is 'beat'.\")\n",
    "    if ytick not in (\"octave\", \"pitch\", \"off\"):\n",
    "        raise ValueError(\"`ytick` must be one of {octave', 'pitch', 'off'}.\")\n",
    "    if not isinstance(xticklabel, bool):\n",
    "        raise TypeError(\"`xticklabel` must be bool.\")\n",
    "    if yticklabel not in (\"auto\", \"name\", \"number\", \"off\"):\n",
    "        raise ValueError(\n",
    "            \"`yticklabel` must be one of {'auto', 'name', 'number', 'off'}.\"\n",
    "        )\n",
    "    if tick_direction not in (\"in\", \"out\", \"inout\"):\n",
    "        raise ValueError(\"`tick_direction` must be one of {'in', 'out', 'inout'}.\")\n",
    "    if label not in (\"x\", \"y\", \"both\", \"off\"):\n",
    "        raise ValueError(\"`label` must be one of {'x', 'y', 'both', 'off'}.\")\n",
    "    if grid not in (\"x\", \"y\", \"both\", \"off\"):\n",
    "        raise ValueError(\"`grid` must be one of {'x', 'y', 'both', 'off'}.\")\n",
    "\n",
    "    # plotting\n",
    "    if pianoroll.ndim > 2:\n",
    "        to_plot = pianoroll.transpose(1, 0, 2)\n",
    "    else:\n",
    "        to_plot = pianoroll.T\n",
    "    if np.issubdtype(pianoroll.dtype, np.bool_) or np.issubdtype(\n",
    "        pianoroll.dtype, np.floating\n",
    "    ):\n",
    "        ax.imshow(\n",
    "            to_plot,\n",
    "            cmap=cmap,\n",
    "            aspect=\"auto\",\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "            origin=\"lower\",\n",
    "            interpolation=\"none\",\n",
    "            alpha = alpha,\n",
    "        )\n",
    "    elif np.issubdtype(pianoroll.dtype, np.integer):\n",
    "        ax.imshow(\n",
    "            to_plot,\n",
    "            cmap=cmap,\n",
    "            aspect=\"auto\",\n",
    "            vmin=0,\n",
    "            vmax=127,\n",
    "            origin=\"lower\",\n",
    "            interpolation=\"none\",\n",
    "            alpha = alpha,\n",
    "        )\n",
    "    else:\n",
    "        raise TypeError(\"Unsupported data type for `pianoroll`.\")\n",
    "\n",
    "    # tick setting\n",
    "    if tick_loc is None:\n",
    "        tick_loc = (\"bottom\", \"left\")\n",
    "    if xtick == \"auto\":\n",
    "        xtick = \"beat\" if beat_resolution is not None else \"step\"\n",
    "    if yticklabel == \"auto\":\n",
    "        yticklabel = \"name\" if ytick == \"octave\" else \"number\"\n",
    "\n",
    "    if preset == \"plain\":\n",
    "        ax.axis(\"off\")\n",
    "    elif preset == \"frame\":\n",
    "        ax.tick_params(\n",
    "            direction=tick_direction,\n",
    "            bottom=False,\n",
    "            top=False,\n",
    "            left=False,\n",
    "            right=False,\n",
    "            labelbottom=False,\n",
    "            labeltop=False,\n",
    "            labelleft=False,\n",
    "            labelright=False,\n",
    "        )\n",
    "    else:\n",
    "        ax.tick_params(\n",
    "            direction=tick_direction,\n",
    "            bottom=(\"bottom\" in tick_loc),\n",
    "            top=(\"top\" in tick_loc),\n",
    "            left=(\"left\" in tick_loc),\n",
    "            right=(\"right\" in tick_loc),\n",
    "            labelbottom=(xticklabel != \"off\"),\n",
    "            labelleft=(yticklabel != \"off\"),\n",
    "            labeltop=False,\n",
    "            labelright=False,\n",
    "        )\n",
    "\n",
    "    # x-axis\n",
    "    if xtick == \"beat\" and preset != \"frame\":\n",
    "        num_beat = pianoroll.shape[0] // beat_resolution\n",
    "        ax.set_xticks(beat_resolution * np.arange(num_beat) - 0.5)\n",
    "        ax.set_xticklabels(\"\")\n",
    "        ax.set_xticks(beat_resolution * (np.arange(num_beat) + 0.5) - 0.5, minor=True)\n",
    "        ax.set_xticklabels(np.arange(x_start, num_beat + 1), minor=True)\n",
    "        ax.tick_params(axis=\"x\", which=\"minor\", width=0)\n",
    "\n",
    "    # y-axis\n",
    "    if ytick == \"octave\":\n",
    "        ax.set_yticks(np.arange(0, num_notes, 12))\n",
    "        if yticklabel == \"name\":\n",
    "            ax.set_yticklabels([\"C{}\".format(i - 2) for i in range(11)])\n",
    "    elif ytick == \"step\":\n",
    "        ax.set_yticks(np.arange(0, num_notes))\n",
    "        if yticklabel == \"name\":\n",
    "            if is_drum:\n",
    "                ax.set_yticklabels(\n",
    "                    [pretty_midi.note_number_to_drum_name(i) for i in range(num_notes)]\n",
    "                )\n",
    "            else:\n",
    "                ax.set_yticklabels(\n",
    "                    [pretty_midi.note_number_to_name(i) for i in range(num_notes)]\n",
    "                )\n",
    "\n",
    "    # axis labels\n",
    "    if label in (\"x\", \"both\"):\n",
    "        if xtick == \"step\" or not xticklabel:\n",
    "            ax.set_xlabel(\"time (step)\")\n",
    "        else:\n",
    "            ax.set_xlabel(\"time (beat)\")\n",
    "\n",
    "    if label in (\"y\", \"both\"):\n",
    "        if is_drum:\n",
    "            ax.set_ylabel(\"key name\")\n",
    "        else:\n",
    "            ax.set_ylabel(\"pitch\")\n",
    "\n",
    "    # grid\n",
    "    if grid != \"off\":\n",
    "        ax.grid(\n",
    "            axis=grid, color=\"k\", linestyle=grid_linestyle, linewidth=grid_linewidth\n",
    "        )\n",
    "\n",
    "    # downbeat boarder\n",
    "    if downbeats is not None and preset != \"plain\":\n",
    "        for step in downbeats:\n",
    "            ax.axvline(x=step, color=\"k\", linewidth=1)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
