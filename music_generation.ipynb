{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import midi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Lambda, Concatenate, LSTM\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "#import tensorflow_probability as tfp # for tf version 2.0.0, tfp version 0.8 is needed \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sys import stdout\n",
    "import random\n",
    "\n",
    "# My code\n",
    "from loading import *\n",
    "from models import *\n",
    "from data import *\n",
    "from midi_to_statematrix import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.0.0\n",
      "GPU is available: False\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"GPU is available: {}\".format(tf.test.is_gpu_available()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'maestro-v2.0.0/maestro-v2.0.0.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call data class\n",
    "data = DataObject(file, what_type = 'train', train_tms = 100, test_tms = 100, fs = 20, window_size = 15)\n",
    "\n",
    "# Create a batch class which we will iterate over\n",
    "train_batch = Batch(data, batch_size = 32, songs_per_batch = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_batch = train_batch.data\n",
    "curr_batch.featurize(use_biaxial = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_binary_loss_seq(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, [-1, 78])\n",
    "    y_pred = tf.reshape(y_pred, [-1, 78])\n",
    "    \n",
    "    bce = tf.keras.losses.BinaryCrossentropy()\n",
    "    \n",
    "    return bce(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = biaxial_target_model_oneseq(curr_batch)\n",
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(), optimizer = Adam(learning_rate=0.0005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 85, 78, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_batch.target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer_context (InputLa (32, 2, 100, 78)          0         \n",
      "_________________________________________________________________\n",
      "Encoder_layer_1 (Lambda)     (64, 100, 78)             0         \n",
      "_________________________________________________________________\n",
      "Encoder_lstm_1 (LSTM)        (64, 512)                 1210368   \n",
      "_________________________________________________________________\n",
      "Encoder_dense_1 (Dense)      (64, 512)                 262656    \n",
      "_________________________________________________________________\n",
      "Encoder_output (Dense)       (64, 10)                  5130      \n",
      "_________________________________________________________________\n",
      "Encoder_concat_representatio (32, 20)                  0         \n",
      "_________________________________________________________________\n",
      "Encoder_output_reshape (Lamb (32, 85, 78, 20)          0         \n",
      "_________________________________________________________________\n",
      "Decoder_layer_1 (Lambda)     (32, 85, 78, 23)          0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (2496, 85, 23)            0         \n",
      "_________________________________________________________________\n",
      "Decoder_time_lstm_1 (LSTM)   (2496, 85, 200)           179200    \n",
      "_________________________________________________________________\n",
      "Decoder_time_lstm_2 (LSTM)   (2496, 85, 200)           320800    \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (2720, 78, 200)           0         \n",
      "_________________________________________________________________\n",
      "Decoder_note_lstm_1 (LSTM)   (2720, 78, 100)           120400    \n",
      "_________________________________________________________________\n",
      "Decoder_note_lstm_2 (LSTM)   (2720, 78, 1)             408       \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (32, 85, 78)              0         \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (32, 78)                  0         \n",
      "=================================================================\n",
      "Total params: 2,098,962\n",
      "Trainable params: 2,098,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputize(curr_batch):\n",
    "    \n",
    "    train_target = curr_batch.target\n",
    "    train_target = tf.roll(train_target, shift=1, axis=1)\n",
    "    train_target = train_target.numpy()\n",
    "    train_target[:,0,:] = curr_batch.context[:,-1,-1,:]\n",
    "    \n",
    "    return [curr_batch.context, train_target]\n",
    "\n",
    "def generate(train_batch):\n",
    "    \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
    "    while True:\n",
    "        new_batch    = next(train_batch)\n",
    "        new_batch.featurize(use_biaxial = False)\n",
    "        yield ([tf.convert_to_tensor(new_batch.context, dtype = tf.float32), \n",
    "                tf.convert_to_tensor(new_batch.target_train, dtype = tf.float32)], \n",
    "               tf.convert_to_tensor(new_batch.target_pred, dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict([tf.convert_to_tensor(curr_batch.context, dtype = tf.float32), \n",
    "                tf.convert_to_tensor(curr_batch.target_train, dtype = tf.float32)], steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_batch.target_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2810245 , 0.27203536, 0.28445378, ..., 0.29772553, 0.2977431 ,\n",
       "        0.29775432],\n",
       "       [0.2810251 , 0.27203637, 0.28445524, ..., 0.29772615, 0.29774356,\n",
       "        0.29775462],\n",
       "       [0.2810286 , 0.27204183, 0.28446218, ..., 0.297738  , 0.2977559 ,\n",
       "        0.29776746],\n",
       "       ...,\n",
       "       [0.28102383, 0.27203327, 0.2844499 , ..., 0.29771766, 0.29773495,\n",
       "        0.29774594],\n",
       "       [0.28102252, 0.2720318 , 0.28444922, ..., 0.29773825, 0.2977559 ,\n",
       "        0.29776722],\n",
       "       [0.28102183, 0.27202824, 0.28444186, ..., 0.29774076, 0.2977584 ,\n",
       "        0.29776973]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "                    generate(train_batch),\n",
    "                    steps_per_epoch=1024,\n",
    "                    epochs=5)\n",
    "model.save_weights('model_biaxial_oneseq_nofeat.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_rolled_target.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict([tf.convert_to_tensor(curr_batch.context, dtype = tf.float32), \n",
    "                tf.convert_to_tensor(curr_batch.target_train, dtype = tf.float32)], steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_batch.target_pred[57,2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[57,5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[:,:,:].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_batch.target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoder_simple(model):\n",
    "\n",
    "    input_shape = model.get_layer(\"lambda_2\").output.shape\n",
    "\n",
    "    input_embedding = Input(batch_shape = \n",
    "                          (input_shape[0],  # batch_size\n",
    "                           None,            # timesteps ()\n",
    "                           input_shape[2]),  # note_size\n",
    "                          name=\"Input_layer_embedding\")\n",
    "\n",
    "    decoder, _, _ = LSTM(units = 512, \n",
    "                      return_sequences = True,\n",
    "                      return_state = True,\n",
    "                      activation = 'tanh',\n",
    "                      name = 'Decoder_lstm_1')(input_embedding)\n",
    "\n",
    "    decoder = LSTM(units = 88, \n",
    "                      activation = 'sigmoid',\n",
    "                      name = 'Decoder_lstm_2')(decoder)\n",
    "\n",
    "    new_model = Model(input_embedding, decoder)\n",
    "    \n",
    "    names = {layer.name:idx for idx, layer in enumerate(model.layers)}\n",
    "    weights = model.get_weights()\n",
    "\n",
    "    for idx, layer in enumerate(new_model.layers):\n",
    "        if layer.name in names.keys():\n",
    "            new_model.layers[idx].set_weights(weights[names[layer.name]])\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder = get_decoder_simple(model)\n",
    "#decoder.summary()\n",
    "\n",
    "#weights_list = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model([curr_batch.context, curr_batch.target_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create music! (inefficient version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_music(model, input_context):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to change target so that it gives the first 50 non silent timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_target = curr_batch.target.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igor = np.nonzero(curr_batch.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_index = np.nonzero(np.r_[1, np.diff(igor[0])[:-1]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_note_index = igor[1][first_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, idx in enumerate(first_note_index):\n",
    "    change_target[batch,(idx+50):,:] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate midi and see how it looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piano_roll_to_pretty_midi(piano_roll, fs=100, program=0):\n",
    "    \n",
    "    piano_roll = np.pad(piano_roll, [(0, 0), (20,20)], 'constant', constant_values=0)\n",
    "    \n",
    "    piano_roll = np.transpose(piano_roll)\n",
    "    \n",
    "    notes, frames = piano_roll.shape\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=program)\n",
    "\n",
    "    # pad 1 column of zeros so we can acknowledge inital and ending events\n",
    "    piano_roll = np.pad(piano_roll, [(0, 0), (1, 1)], 'constant')\n",
    "\n",
    "    # use changes in velocities to find note on / note off events\n",
    "    velocity_changes = np.nonzero(np.diff(piano_roll).T)\n",
    "\n",
    "    # keep track on velocities and note on times\n",
    "    prev_velocities = np.zeros(notes, dtype=int)\n",
    "    note_on_time = np.zeros(notes)\n",
    "\n",
    "    for time, note in zip(*velocity_changes):\n",
    "        # use time + 1 because of padding above\n",
    "        velocity = piano_roll[note, time + 1]\n",
    "        time = time / fs\n",
    "        if velocity > 0:\n",
    "            if prev_velocities[note] == 0:\n",
    "                note_on_time[note] = time\n",
    "                prev_velocities[note] = velocity\n",
    "        else:\n",
    "            pm_note = pretty_midi.Note(\n",
    "                velocity=prev_velocities[note],\n",
    "                pitch=note,\n",
    "                start=note_on_time[note],\n",
    "                end=time)\n",
    "            instrument.notes.append(pm_note)\n",
    "            prev_velocities[note] = 0\n",
    "    pm.instruments.append(instrument)\n",
    "    return pm\n",
    "\n",
    "def extract_piano_roll(predicted_pr, threshold):\n",
    "    \n",
    "    predicted_pr[predicted_pr >= threshold] = 1\n",
    "    predicted_pr[predicted_pr < threshold] = 0\n",
    "    \n",
    "    return predicted_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_midi = piano_roll_to_pretty_midi(curr_batch.target[0,:,:], fs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_midi.write('example_target.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_target = extract_piano_roll(output[0,:,:], threshold = 0.2)\n",
    "predicted_midi = piano_roll_to_pretty_midi(predicted_target, fs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_midi.write('example_predicted.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "print(predicted_target[idx,:])\n",
    "print(curr_batch.target[0,idx,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_batch.link[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_data = pretty_midi.PrettyMIDI('maestro-v2.0.0/'+'2006/MIDI-Unprocessed_01_R1_2006_01-09_ORIG_MID--AUDIO_01_R1_2006_01_Track01_wav.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_data.estimate_tempo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_shape  = curr_batch.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igor = tf.zeros((128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_igor=tf.tile(tf.expand_dims(igor, 1), [1,target_shape[1],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.concat([curr_batch.target, new_igor], axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_batch.target[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igor = tf.convert_to_tensor([[1,1,1,1], [2,2,2,2], [3,3,3,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reshape(igor, [4,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = lstm(curr_batch.context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_output = K.mean(tf.reshape(output, [128, 59, 100]), axis = -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_output = tf.tile(tf.expand_dims(res_output, 1), [1,150,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.mean(res_output, axis = -2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_context_ = Input((None, 2), name=\"Input_layer_contxt_xy\") # [num_pts, 2]\n",
    "input_target_x = Input((None, 1), name=\"Input_layer_target_x\")  # [num_pts, 1]\n",
    "\n",
    "encoder = input_context_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_batch.context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
