{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Lambda, Concatenate, LSTM\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "#import tensorflow_probability as tfp # for tf version 2.0.0, tfp version 0.8 is needed \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sys import stdout\n",
    "import random\n",
    "\n",
    "# My code\n",
    "from loading import *\n",
    "from models import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"GPU is available: {}\".format(tf.test.is_gpu_available()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'maestro-v2.0.0/maestro-v2.0.0.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call data class\n",
    "data = DataObject(file, what_type = 'train', train_sec = 15, test_sec = 5, fs = 20, window_size = 15)\n",
    "\n",
    "# Create a batch class which we will iterate over\n",
    "train_batch = Batch(data, batch_size = 128, songs_per_batch = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_batch = train_batch.data\n",
    "model = simple_model(curr_batch)\n",
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(), optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer_context (InputLa (128, 59, 15, 88)         0         \n",
      "_________________________________________________________________\n",
      "Reshape_layer_1 (Lambda)     (7552, 15, 88)            0         \n",
      "_________________________________________________________________\n",
      "Encoder_lstm_1 (LSTM)        (7552, 15, 512)           1230848   \n",
      "_________________________________________________________________\n",
      "Encoder_lstm_2 (LSTM)        (7552, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "Encoder_dense_1 (Dense)      (7552, 512)               262656    \n",
      "_________________________________________________________________\n",
      "Encoder_dense_2 (Dense)      (7552, 256)               131328    \n",
      "_________________________________________________________________\n",
      "Encoder_dense_3 (Dense)      (7552, 10)                2570      \n",
      "_________________________________________________________________\n",
      "Mean_representation_layer (L (128, 10)                 0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (128, 100, 10)            0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (128, 100, 98)            0         \n",
      "_________________________________________________________________\n",
      "Decoder_lstm_1 (LSTM)        [(128, 100, 512), (128, 5 1251328   \n",
      "_________________________________________________________________\n",
      "Decoder_lstm_2 (LSTM)        [(128, 100, 88), (128, 88 211552    \n",
      "=================================================================\n",
      "Total params: 5,189,482\n",
      "Trainable params: 5,189,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(train_batch):\n",
    "    \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
    "    while True:\n",
    "        new_batch = next(train_batch)\n",
    "        yield ([new_batch.context, new_batch.target], new_batch.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 3042s 3s/step - loss: 0.0372\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 3047s 3s/step - loss: 0.0154\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "                    generate(train_batch),\n",
    "                    steps_per_epoch=1000,\n",
    "                    epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03718636266607791, 0.015437088180333377]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict([curr_batch.context, curr_batch.target], steps = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2696599, shape=(88,), dtype=float32, numpy=\n",
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_batch.target[0,6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.70243901e-06, 5.52789024e-05, 1.79611234e-04, 1.12407703e-04,\n",
       "       3.00861080e-04, 4.02287260e-04, 9.27054934e-05, 2.36979425e-02,\n",
       "       8.84433030e-05, 7.80734190e-05, 4.11175337e-04, 8.23952782e-04,\n",
       "       1.80022523e-03, 6.96475734e-04, 1.19857641e-03, 7.39105931e-03,\n",
       "       1.12812640e-03, 3.75009561e-03, 1.59647316e-03, 9.78283465e-01,\n",
       "       4.01845988e-04, 4.36160044e-04, 5.41753648e-03, 9.55974101e-04,\n",
       "       3.11712874e-03, 1.15243101e-03, 3.14946496e-03, 5.08662593e-03,\n",
       "       3.35655757e-03, 3.84370866e-03, 8.07309407e-04, 6.04331121e-02,\n",
       "       1.02264108e-03, 8.04050942e-04, 2.84986906e-02, 3.01948981e-03,\n",
       "       1.45442309e-02, 8.04961100e-03, 7.30445096e-03, 9.62767005e-01,\n",
       "       3.77063872e-03, 5.24997246e-03, 3.11924564e-03, 9.95260477e-01,\n",
       "       7.74603279e-04, 9.23627755e-04, 9.86645460e-01, 3.70945525e-03,\n",
       "       1.14304014e-02, 6.14788989e-03, 1.23634832e-02, 7.11906888e-03,\n",
       "       5.62151009e-03, 1.68517313e-03, 6.74427662e-04, 2.42075231e-02,\n",
       "       3.79200326e-04, 6.80246099e-04, 7.68617634e-03, 8.80211068e-04,\n",
       "       1.67925295e-03, 1.86840683e-04, 1.83587475e-03, 2.93387537e-04,\n",
       "       4.61010932e-04, 1.82510208e-04, 9.55472715e-05, 1.39225309e-03,\n",
       "       4.86913304e-05, 1.18651595e-04, 3.44877277e-04, 4.20101460e-05,\n",
       "       1.42801728e-04, 1.62843135e-04, 1.37862895e-04, 1.20008255e-04,\n",
       "       1.95198110e-04, 1.33075519e-04, 6.46673216e-05, 2.50111654e-04,\n",
       "       6.39081991e-05, 1.48866398e-04, 2.28900535e-04, 5.65362934e-05,\n",
       "       1.00221601e-04, 3.80760939e-05, 2.24462710e-05, 1.19066617e-05],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0,7,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate midi and see how it looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 88])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "igor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 100)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "igor = curr_batch.target[0,:,:]\n",
    "np.transpose(igor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piano_roll_to_pretty_midi(piano_roll, fs=100, program=0):\n",
    "    \n",
    "    piano_roll = np.pad(piano_roll, [(0, 0), (20,20)], 'constant', constant_values=0)\n",
    "    \n",
    "    piano_roll = np.transpose(piano_roll)\n",
    "    \n",
    "    notes, frames = piano_roll.shape\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=program)\n",
    "\n",
    "    # pad 1 column of zeros so we can acknowledge inital and ending events\n",
    "    piano_roll = np.pad(piano_roll, [(0, 0), (1, 1)], 'constant')\n",
    "\n",
    "    # use changes in velocities to find note on / note off events\n",
    "    velocity_changes = np.nonzero(np.diff(piano_roll).T)\n",
    "\n",
    "    # keep track on velocities and note on times\n",
    "    prev_velocities = np.zeros(notes, dtype=int)\n",
    "    note_on_time = np.zeros(notes)\n",
    "\n",
    "    for time, note in zip(*velocity_changes):\n",
    "        # use time + 1 because of padding above\n",
    "        velocity = piano_roll[note, time + 1]\n",
    "        time = time / fs\n",
    "        if velocity > 0:\n",
    "            if prev_velocities[note] == 0:\n",
    "                note_on_time[note] = time\n",
    "                prev_velocities[note] = velocity\n",
    "        else:\n",
    "            pm_note = pretty_midi.Note(\n",
    "                velocity=prev_velocities[note],\n",
    "                pitch=note,\n",
    "                start=note_on_time[note],\n",
    "                end=time)\n",
    "            instrument.notes.append(pm_note)\n",
    "            prev_velocities[note] = 0\n",
    "    pm.instruments.append(instrument)\n",
    "    return pm\n",
    "\n",
    "def extract_piano_roll(predicted_pr, threshold):\n",
    "    \n",
    "    predicted_pr[predicted_pr >= threshold] = 1\n",
    "    predicted_pr[predicted_pr < threshold] = 0\n",
    "    \n",
    "    return predicted_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_midi = piano_roll_to_pretty_midi(curr_batch.target[0,:,:], fs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_midi.write('example_target.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_target = extract_piano_roll(output[0,:,:], threshold = 0.5)\n",
    "predicted_midi = piano_roll_to_pretty_midi(predicted_target, fs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_midi.write('example_predicted.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(88,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "idx = 10\n",
    "print(predicted_target[idx,:])\n",
    "print(curr_batch.target[0,idx,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2006/MIDI-Unprocessed_01_R1_2006_01-09_ORIG_MID--AUDIO_01_R1_2006_01_Track01_wav.midi'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_batch.link[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_data = pretty_midi.PrettyMIDI('maestro-v2.0.0/'+'2006/MIDI-Unprocessed_01_R1_2006_01-09_ORIG_MID--AUDIO_01_R1_2006_01_Track01_wav.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194.1653240798144"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_data.estimate_tempo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_shape  = curr_batch.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igor = tf.zeros((128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_igor=tf.tile(tf.expand_dims(igor, 1), [1,target_shape[1],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.concat([curr_batch.target, new_igor], axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_batch.target[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igor = tf.convert_to_tensor([[1,1,1,1], [2,2,2,2], [3,3,3,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reshape(igor, [4,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = lstm(curr_batch.context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_output = K.mean(tf.reshape(output, [128, 59, 100]), axis = -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_output = tf.tile(tf.expand_dims(res_output, 1), [1,150,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.mean(res_output, axis = -2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_context_ = Input((None, 2), name=\"Input_layer_contxt_xy\") # [num_pts, 2]\n",
    "input_target_x = Input((None, 1), name=\"Input_layer_target_x\")  # [num_pts, 1]\n",
    "\n",
    "encoder = input_context_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_batch.context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
